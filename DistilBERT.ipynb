{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceType": "datasetVersion",
          "sourceId": 8133322,
          "datasetId": 4773162,
          "databundleVersionId": 8253352
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 8084649,
          "datasetId": 4772280,
          "databundleVersionId": 8200955
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 8031300,
          "datasetId": 4733852,
          "databundleVersionId": 8144267
        }
      ],
      "dockerImageVersionId": 30684,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Packages"
      ],
      "metadata": {
        "id": "MppMmfuZttlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install sklearn\n",
        "!pip3 install transformers\n",
        "!pip3 install sentence-transformers\n",
        "!pip install early_stopping"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-16T08:52:06.122258Z",
          "iopub.execute_input": "2024-04-16T08:52:06.12304Z",
          "iopub.status.idle": "2024-04-16T08:52:47.89614Z",
          "shell.execute_reply.started": "2024-04-16T08:52:06.123004Z",
          "shell.execute_reply": "2024-04-16T08:52:47.894903Z"
        },
        "trusted": true,
        "id": "YB6vQyZ8JJwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.functional import one_hot\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from datasets import load_metric\n",
        "from datasets import Dataset\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from transformers import DistilBertConfig, DistilBertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from early_stopping import EarlyStopping"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-16T08:52:47.898574Z",
          "iopub.execute_input": "2024-04-16T08:52:47.898929Z",
          "iopub.status.idle": "2024-04-16T08:52:47.910493Z",
          "shell.execute_reply.started": "2024-04-16T08:52:47.898899Z",
          "shell.execute_reply": "2024-04-16T08:52:47.909419Z"
        },
        "trusted": true,
        "id": "wKRBylMjJJwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DISTILBERT MODEL"
      ],
      "metadata": {
        "id": "ADLU0e2PRt9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def labels_to_text(labels, label_mapping):\n",
        "    # Reverse the label_mapping dictionary to map numbers to category names\n",
        "\n",
        "    reverse_mapping = {value: key for key, value in label_mapping.items()}\n",
        "\n",
        "    # Convert list of numbers to list of text using the reversed mapping\n",
        "    text_labels = [reverse_mapping[label] for label in labels if label in reverse_mapping]\n",
        "\n",
        "    return text_labels"
      ],
      "metadata": {
        "id": "OqX5KJYgYHYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your dataset class\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx], self.labels[idx]\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=12)\n",
        "\n",
        "early_stopper = EarlyStopping(\n",
        "    depth=5,\n",
        "    ignore=20,\n",
        "    method='consistency'\n",
        ")\n",
        "\n",
        "# Load your dataset and label mapping\n",
        "with open('/path/augmented/dataset.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "label_mapping = {\n",
        "    \"Politics\": 0,\n",
        "    \"Health\": 1,\n",
        "    \"Finance\": 2,\n",
        "    \"Travel\": 3,\n",
        "    \"Food\": 4,\n",
        "    \"Education\": 5,\n",
        "    \"Environment\": 6,\n",
        "    \"Fashion\": 7,\n",
        "    \"Science\": 8,\n",
        "    \"Sports\": 9,\n",
        "    \"Technology\": 10,\n",
        "    \"Entertainment\": 11\n",
        "}\n",
        "\n",
        "# Process your dataset\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "for label, sentences in data.items():\n",
        "    if label in label_mapping:\n",
        "        for sentence in sentences:\n",
        "            texts.append(sentence)\n",
        "            label_tensor = label_mapping[label]  # Single integer label\n",
        "            labels.append(label_tensor)\n",
        "    else:\n",
        "        print(f\"Warning: Label '{label}' not found in label mapping.\")\n",
        "\n",
        "# Tokenize texts\n",
        "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Convert labels to PyTorch tensor\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(inputs['input_ids'], labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create DataLoader instances\n",
        "train_dataset = MyDataset(train_texts, train_labels)\n",
        "test_dataset = MyDataset(test_texts, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Train the model\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=inputs.squeeze(1), labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(input_ids=inputs.squeeze(1), labels=labels)\n",
        "            loss = outputs.loss\n",
        "            test_loss += loss.item()\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.argmax(logits, dim=1)\n",
        "            y_true.extend(labels.tolist())\n",
        "            y_pred.extend(predictions.tolist())\n",
        "    test_loss /= len(test_loader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss}, Test Loss: {test_loss}\")\n",
        "    print(classification_report(y_true, y_pred, target_names=label_mapping.keys()))\n",
        "    if early_stopper.check(test_loss):\n",
        "        print('BREAKING THE TRAINING LOOP')\n",
        "        break\n",
        "\n",
        "    # Update the scheduler\n",
        "    scheduler.step(test_loss)\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Learning rate: {lr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fms8bwERxAf",
        "outputId": "95ddf108-5579-4e13-a424-cf4ac7419953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Train Loss: 1.843723941933025, Test Loss: 0.8988357782363892\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.85      0.88      0.87        33\n",
            "       Health       0.76      0.93      0.84        30\n",
            "      Finance       0.80      0.90      0.85        41\n",
            "       Travel       0.87      0.97      0.92        35\n",
            "         Food       0.97      0.94      0.95        32\n",
            "    Education       0.90      1.00      0.95        36\n",
            "  Environment       0.94      0.48      0.64        33\n",
            "      Fashion       0.83      1.00      0.91        24\n",
            "      Science       0.76      0.52      0.62        25\n",
            "       Sports       0.97      1.00      0.98        31\n",
            "   Technology       0.68      0.68      0.68        28\n",
            "Entertainment       0.96      0.90      0.93        29\n",
            "\n",
            "     accuracy                           0.86       377\n",
            "    macro avg       0.86      0.85      0.84       377\n",
            " weighted avg       0.86      0.86      0.85       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 2/20, Train Loss: 0.5972506653178822, Test Loss: 0.5592879448086023\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.58      0.97      0.73        33\n",
            "       Health       0.81      0.83      0.82        30\n",
            "      Finance       0.97      0.73      0.83        41\n",
            "       Travel       0.91      0.91      0.91        35\n",
            "         Food       0.93      0.84      0.89        32\n",
            "    Education       0.90      0.78      0.84        36\n",
            "  Environment       0.77      0.61      0.68        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.87      0.52      0.65        25\n",
            "       Sports       0.94      0.94      0.94        31\n",
            "   Technology       0.62      0.82      0.71        28\n",
            "Entertainment       0.93      0.93      0.93        29\n",
            "\n",
            "     accuracy                           0.82       377\n",
            "    macro avg       0.84      0.82      0.82       377\n",
            " weighted avg       0.85      0.82      0.82       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 3/20, Train Loss: 0.24787683446298947, Test Loss: 0.5405121703321735\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.81      0.91      0.86        33\n",
            "       Health       0.85      0.77      0.81        30\n",
            "      Finance       0.88      0.93      0.90        41\n",
            "       Travel       0.80      0.94      0.87        35\n",
            "         Food       0.91      0.94      0.92        32\n",
            "    Education       0.97      0.78      0.86        36\n",
            "  Environment       0.78      0.64      0.70        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.91      0.40      0.56        25\n",
            "       Sports       0.96      0.87      0.92        31\n",
            "   Technology       0.58      0.79      0.67        28\n",
            "Entertainment       0.81      1.00      0.89        29\n",
            "\n",
            "     accuracy                           0.84       377\n",
            "    macro avg       0.85      0.83      0.82       377\n",
            " weighted avg       0.85      0.84      0.83       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 4/20, Train Loss: 0.13286738551475785, Test Loss: 0.40613525997226435\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.93      0.79      0.85        33\n",
            "       Health       0.83      0.83      0.83        30\n",
            "      Finance       0.90      0.90      0.90        41\n",
            "       Travel       0.80      0.94      0.87        35\n",
            "         Food       0.89      0.97      0.93        32\n",
            "    Education       0.94      0.83      0.88        36\n",
            "  Environment       0.76      0.88      0.82        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.94      0.60      0.73        25\n",
            "       Sports       0.97      0.97      0.97        31\n",
            "   Technology       0.73      0.79      0.76        28\n",
            "Entertainment       0.96      0.93      0.95        29\n",
            "\n",
            "     accuracy                           0.87       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.87      0.87       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 5/20, Train Loss: 0.0580186280337247, Test Loss: 0.488962324646612\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.88      0.88      0.88        33\n",
            "       Health       0.84      0.70      0.76        30\n",
            "      Finance       0.91      0.95      0.93        41\n",
            "       Travel       0.97      0.94      0.96        35\n",
            "         Food       0.83      0.94      0.88        32\n",
            "    Education       0.97      0.86      0.91        36\n",
            "  Environment       0.76      0.88      0.82        33\n",
            "      Fashion       0.92      1.00      0.96        24\n",
            "      Science       0.86      0.48      0.62        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.61      0.79      0.69        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.87       377\n",
            "    macro avg       0.87      0.86      0.86       377\n",
            " weighted avg       0.87      0.87      0.87       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 6/20, Train Loss: 0.02152777647768909, Test Loss: 0.4793242160618926\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.86      0.91      0.88        33\n",
            "       Health       0.82      0.90      0.86        30\n",
            "      Finance       0.90      0.93      0.92        41\n",
            "       Travel       0.94      0.91      0.93        35\n",
            "         Food       1.00      0.78      0.88        32\n",
            "    Education       0.91      0.89      0.90        36\n",
            "  Environment       0.73      0.82      0.77        33\n",
            "      Fashion       0.92      1.00      0.96        24\n",
            "      Science       0.94      0.60      0.73        25\n",
            "       Sports       0.94      0.94      0.94        31\n",
            "   Technology       0.69      0.79      0.73        28\n",
            "Entertainment       0.94      1.00      0.97        29\n",
            "\n",
            "     accuracy                           0.88       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.88      0.87       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 7/20, Train Loss: 0.019415470483628187, Test Loss: 0.4664807925000787\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.85      0.88      0.87        33\n",
            "       Health       0.85      0.73      0.79        30\n",
            "      Finance       0.93      0.93      0.93        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.88      0.91      0.89        32\n",
            "    Education       0.92      0.92      0.92        36\n",
            "  Environment       0.77      0.82      0.79        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.83      0.60      0.70        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.72      0.82      0.77        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.88       377\n",
            "    macro avg       0.87      0.87      0.87       377\n",
            " weighted avg       0.88      0.88      0.87       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 8/20, Train Loss: 0.010540856708857146, Test Loss: 0.47622653321983915\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.86      0.91      0.88        33\n",
            "       Health       0.84      0.87      0.85        30\n",
            "      Finance       0.93      0.93      0.93        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       1.00      0.78      0.88        32\n",
            "    Education       0.91      0.89      0.90        36\n",
            "  Environment       0.72      0.79      0.75        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.68      0.82      0.74        28\n",
            "Entertainment       0.94      1.00      0.97        29\n",
            "\n",
            "     accuracy                           0.88       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.88      0.87       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 9/20, Train Loss: 0.00810502174903046, Test Loss: 0.47541494834392023\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.85      0.88      0.87        33\n",
            "       Health       0.84      0.87      0.85        30\n",
            "      Finance       0.93      0.93      0.93        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.96      0.78      0.86        32\n",
            "    Education       0.91      0.89      0.90        36\n",
            "  Environment       0.70      0.79      0.74        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.68      0.82      0.74        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.87       377\n",
            "    macro avg       0.87      0.87      0.87       377\n",
            " weighted avg       0.88      0.87      0.87       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 10/20, Train Loss: 0.006674703684720126, Test Loss: 0.48514784849248827\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.88      0.88      0.88        33\n",
            "       Health       0.84      0.87      0.85        30\n",
            "      Finance       0.93      0.93      0.93        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.96      0.81      0.88        32\n",
            "    Education       0.91      0.86      0.89        36\n",
            "  Environment       0.72      0.79      0.75        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.67      0.86      0.75        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.87       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.87      0.87       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 11/20, Train Loss: 0.005549506563693285, Test Loss: 0.48692458557585877\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.88      0.88      0.88        33\n",
            "       Health       0.84      0.87      0.85        30\n",
            "      Finance       0.93      0.93      0.93        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.96      0.84      0.90        32\n",
            "    Education       0.91      0.89      0.90        36\n",
            "  Environment       0.74      0.79      0.76        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.69      0.86      0.76        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.88       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.88      0.88       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 12/20, Train Loss: 0.004946062476797537, Test Loss: 0.49768430171146366\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.88      0.88      0.88        33\n",
            "       Health       0.79      0.87      0.83        30\n",
            "      Finance       0.90      0.93      0.92        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.97      0.88      0.92        32\n",
            "    Education       0.91      0.89      0.90        36\n",
            "  Environment       0.77      0.73      0.75        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.69      0.86      0.76        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.88       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.88      0.87       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 13/20, Train Loss: 0.004072391965680502, Test Loss: 0.506628607341554\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.88      0.88      0.88        33\n",
            "       Health       0.81      0.87      0.84        30\n",
            "      Finance       0.90      0.93      0.92        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.96      0.84      0.90        32\n",
            "    Education       0.91      0.86      0.89        36\n",
            "  Environment       0.74      0.76      0.75        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.69      0.86      0.76        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.87       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.87      0.87       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 14/20, Train Loss: 0.003570122102444822, Test Loss: 0.5057176246191375\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.88      0.88      0.88        33\n",
            "       Health       0.81      0.87      0.84        30\n",
            "      Finance       0.90      0.93      0.92        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.96      0.84      0.90        32\n",
            "    Education       0.91      0.89      0.90        36\n",
            "  Environment       0.74      0.76      0.75        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.71      0.86      0.77        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.88       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.88      0.87       377\n",
            "\n",
            "Learning rate: 5e-05\n",
            "Epoch 15/20, Train Loss: 0.0030977276238528164, Test Loss: 0.5142378878275243\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.88      0.88      0.88        33\n",
            "       Health       0.81      0.87      0.84        30\n",
            "      Finance       0.90      0.93      0.92        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.96      0.84      0.90        32\n",
            "    Education       0.91      0.86      0.89        36\n",
            "  Environment       0.74      0.76      0.75        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.69      0.86      0.76        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.87       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.87      0.87       377\n",
            "\n",
            "Learning rate: 5e-06\n",
            "Epoch 16/20, Train Loss: 0.002856779775836251, Test Loss: 0.5150891949306242\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.88      0.88      0.88        33\n",
            "       Health       0.81      0.87      0.84        30\n",
            "      Finance       0.90      0.93      0.92        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.96      0.84      0.90        32\n",
            "    Education       0.91      0.86      0.89        36\n",
            "  Environment       0.74      0.76      0.75        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.69      0.86      0.76        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.87       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.87      0.87       377\n",
            "\n",
            "Learning rate: 5e-06\n",
            "Epoch 17/20, Train Loss: 0.0029512859965589913, Test Loss: 0.5152954974134142\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.88      0.88      0.88        33\n",
            "       Health       0.81      0.87      0.84        30\n",
            "      Finance       0.90      0.93      0.92        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.96      0.84      0.90        32\n",
            "    Education       0.91      0.86      0.89        36\n",
            "  Environment       0.74      0.76      0.75        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.69      0.86      0.76        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.87       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.87      0.87       377\n",
            "\n",
            "Learning rate: 5e-06\n",
            "Epoch 18/20, Train Loss: 0.002834215197204189, Test Loss: 0.5153683253253499\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.88      0.88      0.88        33\n",
            "       Health       0.81      0.87      0.84        30\n",
            "      Finance       0.90      0.93      0.92        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.96      0.84      0.90        32\n",
            "    Education       0.91      0.86      0.89        36\n",
            "  Environment       0.74      0.76      0.75        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.69      0.86      0.76        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.87       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.87      0.87       377\n",
            "\n",
            "Learning rate: 5e-06\n",
            "Epoch 19/20, Train Loss: 0.0028487820093604653, Test Loss: 0.5160140727530234\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.88      0.88      0.88        33\n",
            "       Health       0.81      0.87      0.84        30\n",
            "      Finance       0.90      0.93      0.92        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.96      0.84      0.90        32\n",
            "    Education       0.91      0.86      0.89        36\n",
            "  Environment       0.74      0.76      0.75        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.69      0.86      0.76        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.87       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.87      0.87       377\n",
            "\n",
            "Learning rate: 5e-06\n",
            "Epoch 20/20, Train Loss: 0.002748188922520388, Test Loss: 0.5160489774425514\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     Politics       0.88      0.88      0.88        33\n",
            "       Health       0.81      0.87      0.84        30\n",
            "      Finance       0.90      0.93      0.92        41\n",
            "       Travel       0.94      0.94      0.94        35\n",
            "         Food       0.96      0.84      0.90        32\n",
            "    Education       0.91      0.86      0.89        36\n",
            "  Environment       0.74      0.76      0.75        33\n",
            "      Fashion       0.89      1.00      0.94        24\n",
            "      Science       0.88      0.60      0.71        25\n",
            "       Sports       0.97      0.94      0.95        31\n",
            "   Technology       0.69      0.86      0.76        28\n",
            "Entertainment       0.93      0.97      0.95        29\n",
            "\n",
            "     accuracy                           0.87       377\n",
            "    macro avg       0.88      0.87      0.87       377\n",
            " weighted avg       0.88      0.87      0.87       377\n",
            "\n",
            "Learning rate: 5e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path for saving the model\n",
        "model_path = \"distilbert_classifier_model.pth\"\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), model_path)\n",
        "\n",
        "print(\"Trained model saved at:\", model_path)\n"
      ],
      "metadata": {
        "id": "zOtU9g66tCHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import csv\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "import pandas as pd\n",
        "\n",
        "# Load the saved model\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=12)\n",
        "model.load_state_dict(torch.load(\"distilbert_classifier_model.pth\", map_location=torch.device('cpu')))\n",
        "model.eval()\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Read text from the input file\n",
        "input_file = \"path/test_shuffle.txt\"\n",
        "with open(input_file, \"r\") as f:\n",
        "    texts = f.readlines()\n",
        "\n",
        "# Tokenize the text\n",
        "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "# Map predicted labels to classes\n",
        "predicted_labels = torch.argmax(logits, dim=1)\n",
        "label_mapping = {\n",
        "    0: \"Politics\",\n",
        "    1: \"Health\",\n",
        "    2: \"Finance\",\n",
        "    3: \"Travel\",\n",
        "    4: \"Food\",\n",
        "    5: \"Education\",\n",
        "    6: \"Environment\",\n",
        "    7: \"Fashion\",\n",
        "    8: \"Science\",\n",
        "    9: \"Sports\",\n",
        "    10: \"Technology\",\n",
        "    11: \"Entertainment\"\n",
        "}\n",
        "predicted_classes = [label_mapping[label.item()] for label in predicted_labels]\n",
        "\n",
        "# Save results to CSV file\n",
        "output_csv = \"/path/inference_results.csv\"\n",
        "df = pd.DataFrame({\"ID\": range(len(texts)), \"Label\": predicted_classes})\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(\"Inference results saved to:\", output_csv)\n"
      ],
      "metadata": {
        "id": "xtjC52Q8zKto"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}